{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Optional, Set\n",
    "import time\n",
    "\n",
    "class SketchfabGLTFIntegrator:\n",
    "    \"\"\"\n",
    "    Integrates Sketchfab 3D models into A-Frame scenes when the model\n",
    "    doesn't know how to handle certain objects.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Common A-Frame environment preset objects that the model already handles\n",
    "    KNOWN_OBJECTS = {\n",
    "        'sky', 'ground', 'trees', 'mountain', 'mountains', 'forest', 'desert', \n",
    "        'ocean', 'pyramids', 'egypt', 'snow', 'dust', 'rain', 'particle', 'light',\n",
    "        'sun', 'moon', 'stars', 'clouds', 'fog', 'box', 'sphere', 'cylinder',\n",
    "        'cone', 'plane', 'torus', 'ring'\n",
    "    }\n",
    "    \n",
    "    def __init__(self, api_token: str, download_dir: str = \"./downloaded_models\"):\n",
    "        \"\"\"\n",
    "        Initialize the integrator.\n",
    "        \n",
    "        Args:\n",
    "            api_token: Your Sketchfab API token (get from https://sketchfab.com/settings/password)\n",
    "            download_dir: Directory to save downloaded glTF files\n",
    "        \"\"\"\n",
    "        self.api_token = api_token\n",
    "        self.download_dir = Path(download_dir)\n",
    "        self.download_dir.mkdir(exist_ok=True)\n",
    "        self.base_url = \"https://api.sketchfab.com/v3\"\n",
    "        \n",
    "    def extract_objects_from_prompt(self, prompt: str) -> Set[str]:\n",
    "        \"\"\"\n",
    "        Extract potential objects from the user's prompt.\n",
    "        \n",
    "        Args:\n",
    "            prompt: User's scene description\n",
    "            \n",
    "        Returns:\n",
    "            Set of object names mentioned in prompt\n",
    "        \"\"\"\n",
    "        # Common nouns that might be 3D objects\n",
    "        words = re.findall(r'\\b[a-z]+\\b', prompt.lower())\n",
    "        \n",
    "        # Filter out common stop words and keep potential objects\n",
    "        stop_words = {'a', 'an', 'the', 'with', 'at', 'and', 'or', 'in', 'on', \n",
    "                     'scene', 'light', 'lighting', 'heavy', 'some', 'many'}\n",
    "        \n",
    "        potential_objects = {word for word in words if word not in stop_words}\n",
    "        \n",
    "        return potential_objects\n",
    "    \n",
    "    def find_unknown_objects(self, prompt: str) -> Set[str]:\n",
    "        \"\"\"\n",
    "        Identify objects in the prompt that aren't in the known set.\n",
    "        \n",
    "        Args:\n",
    "            prompt: User's scene description\n",
    "            \n",
    "        Returns:\n",
    "            Set of unknown object names\n",
    "        \"\"\"\n",
    "        all_objects = self.extract_objects_from_prompt(prompt)\n",
    "        unknown = all_objects - self.KNOWN_OBJECTS\n",
    "        \n",
    "        # Filter out very common words that are likely not 3D objects\n",
    "        filtered_unknown = {obj for obj in unknown if len(obj) > 3}\n",
    "        \n",
    "        return filtered_unknown\n",
    "    \n",
    "    def search_model(self, query: str, max_results: int = 5) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Search for 3D models on Sketchfab.\n",
    "        \n",
    "        Args:\n",
    "            query: Search term (e.g., \"car\", \"building\")\n",
    "            max_results: Maximum number of results to return\n",
    "            \n",
    "        Returns:\n",
    "            List of model dictionaries with uid, name, and download info\n",
    "        \"\"\"\n",
    "        search_url = f\"{self.base_url}/search\"\n",
    "        params = {\n",
    "            \"type\": \"models\",\n",
    "            \"q\": query,\n",
    "            \"downloadable\": True,  # Only get downloadable models\n",
    "            \"count\": max_results,\n",
    "            \"sort_by\": \"-likeCount\"  # Sort by popularity\n",
    "        }\n",
    "        \n",
    "        headers = {\n",
    "            \"Authorization\": f\"Token {self.api_token}\"\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(search_url, params=params, headers=headers)\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "            \n",
    "            models = []\n",
    "            for result in data.get(\"results\", []):\n",
    "                if result.get(\"isDownloadable\", False):\n",
    "                    models.append({\n",
    "                        \"uid\": result[\"uid\"],\n",
    "                        \"name\": result[\"name\"],\n",
    "                        \"thumbnail\": result.get(\"thumbnails\", {}).get(\"images\", [{}])[0].get(\"url\"),\n",
    "                        \"viewerUrl\": result.get(\"viewerUrl\", \"\")\n",
    "                    })\n",
    "            \n",
    "            return models\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error searching for '{query}': {e}\")\n",
    "            return []\n",
    "    \n",
    "    def get_download_url(self, model_uid: str) -> Optional[str]:\n",
    "        \"\"\"\n",
    "        Get the download URL for a specific model.\n",
    "        \n",
    "        Args:\n",
    "            model_uid: Unique identifier of the model\n",
    "            \n",
    "        Returns:\n",
    "            Download URL or None if not available\n",
    "        \"\"\"\n",
    "        download_url = f\"{self.base_url}/models/{model_uid}/download\"\n",
    "        headers = {\n",
    "            \"Authorization\": f\"Token {self.api_token}\"\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(download_url, headers=headers)\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "            \n",
    "            # Look for glTF format\n",
    "            gltf_data = data.get(\"gltf\", {})\n",
    "            if gltf_data and \"url\" in gltf_data:\n",
    "                return gltf_data[\"url\"]\n",
    "            \n",
    "            return None\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error getting download URL for model {model_uid}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def download_model(self, model_uid: str, object_name: str) -> Optional[str]:\n",
    "        \"\"\"\n",
    "        Download a glTF model from Sketchfab.\n",
    "        \n",
    "        Args:\n",
    "            model_uid: Unique identifier of the model\n",
    "            object_name: Name to save the file as\n",
    "            \n",
    "        Returns:\n",
    "            Local path to downloaded glTF file or None if download failed\n",
    "        \"\"\"\n",
    "        download_url = self.get_download_url(model_uid)\n",
    "        if not download_url:\n",
    "            print(f\"Could not get download URL for {object_name}\")\n",
    "            return None\n",
    "        \n",
    "        # Create sanitized filename\n",
    "        safe_name = re.sub(r'[^\\w\\-]', '_', object_name)\n",
    "        zip_path = self.download_dir / f\"{safe_name}.zip\"\n",
    "        extract_dir = self.download_dir / safe_name\n",
    "        \n",
    "        try:\n",
    "            print(f\"Downloading {object_name} from {download_url}...\")\n",
    "            response = requests.get(download_url, stream=True)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            # Save the zip file\n",
    "            with open(zip_path, 'wb') as f:\n",
    "                for chunk in response.iter_content(chunk_size=8192):\n",
    "                    f.write(chunk)\n",
    "            \n",
    "            print(f\"Downloaded to {zip_path}, extracting...\")\n",
    "            \n",
    "            # Extract the zip file\n",
    "            extract_dir.mkdir(exist_ok=True)\n",
    "            with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "                zip_ref.extractall(extract_dir)\n",
    "            \n",
    "            # Find the .gltf or .glb file\n",
    "            gltf_files = list(extract_dir.glob(\"**/*.gltf\")) + list(extract_dir.glob(\"**/*.glb\"))\n",
    "            \n",
    "            if gltf_files:\n",
    "                gltf_path = str(gltf_files[0])\n",
    "                print(f\"Successfully extracted glTF to {gltf_path}\")\n",
    "                \n",
    "                # Clean up zip file\n",
    "                zip_path.unlink()\n",
    "                \n",
    "                return gltf_path\n",
    "            else:\n",
    "                print(f\"No glTF file found in downloaded archive for {object_name}\")\n",
    "                return None\n",
    "                \n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error downloading model: {e}\")\n",
    "            return None\n",
    "        except zipfile.BadZipFile as e:\n",
    "            print(f\"Error extracting zip file: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def inject_gltf_into_html(self, html_content: str, object_assets: Dict[str, str]) -> str:\n",
    "        \"\"\"\n",
    "        Inject glTF models into A-Frame HTML.\n",
    "        \n",
    "        Args:\n",
    "            html_content: Original A-Frame HTML\n",
    "            object_assets: Dict mapping object names to local glTF file paths\n",
    "            \n",
    "        Returns:\n",
    "            Modified HTML with glTF models included\n",
    "        \"\"\"\n",
    "        if not object_assets:\n",
    "            return html_content\n",
    "        \n",
    "        # Build <a-assets> section\n",
    "        assets_html = \"    <a-assets>\\n\"\n",
    "        entity_html = \"\"\n",
    "        \n",
    "        for i, (obj_name, file_path) in enumerate(object_assets.items()):\n",
    "            asset_id = f\"{obj_name}_{i}\"\n",
    "            assets_html += f'      <a-asset-item id=\"{asset_id}\" src=\"{file_path}\"></a-asset-item>\\n'\n",
    "            \n",
    "            # Add entity with some default positioning\n",
    "            # Position entities at different locations to avoid overlap\n",
    "            x_pos = (i % 3 - 1) * 5  # -5, 0, 5\n",
    "            z_pos = -10 - (i // 3) * 5\n",
    "            entity_html += f'      <a-entity gltf-model=\"#{asset_id}\" position=\"{x_pos} 0 {z_pos}\" scale=\"1 1 1\"></a-entity>\\n'\n",
    "        \n",
    "        assets_html += \"    </a-assets>\\n\"\n",
    "        \n",
    "        # Find where to inject (after <a-scene> tag)\n",
    "        scene_pattern = r'(<a-scene[^>]*>)'\n",
    "        \n",
    "        if re.search(scene_pattern, html_content):\n",
    "            # Inject assets right after <a-scene>\n",
    "            html_content = re.sub(\n",
    "                scene_pattern,\n",
    "                r'\\1\\n' + assets_html + entity_html,\n",
    "                html_content,\n",
    "                count=1\n",
    "            )\n",
    "        else:\n",
    "            print(\"Warning: Could not find <a-scene> tag in HTML\")\n",
    "        \n",
    "        return html_content\n",
    "    \n",
    "    def process_prompt_and_enhance_html(\n",
    "        self, \n",
    "        prompt: str, \n",
    "        generated_html: str,\n",
    "        auto_download: bool = True\n",
    "    ) -> tuple[str, List[Dict]]:\n",
    "        \"\"\"\n",
    "        Main method: Find unknown objects, search for models, and enhance HTML.\n",
    "        \n",
    "        Args:\n",
    "            prompt: User's scene description\n",
    "            generated_html: HTML generated by the fine-tuned model\n",
    "            auto_download: If True, automatically download the first match for each object\n",
    "            \n",
    "        Returns:\n",
    "            Tuple of (enhanced_html, list of model info dicts)\n",
    "        \"\"\"\n",
    "        unknown_objects = self.find_unknown_objects(prompt)\n",
    "        \n",
    "        if not unknown_objects:\n",
    "            print(\"No unknown objects found in prompt\")\n",
    "            return generated_html, []\n",
    "        \n",
    "        print(f\"Found unknown objects: {unknown_objects}\")\n",
    "        \n",
    "        downloaded_models = {}\n",
    "        all_model_info = []\n",
    "        \n",
    "        for obj in unknown_objects:\n",
    "            print(f\"\\nSearching for '{obj}'...\")\n",
    "            models = self.search_model(obj, max_results=3)\n",
    "            \n",
    "            if not models:\n",
    "                print(f\"No models found for '{obj}'\")\n",
    "                continue\n",
    "            \n",
    "            print(f\"Found {len(models)} models for '{obj}':\")\n",
    "            for i, model in enumerate(models):\n",
    "                print(f\"  {i+1}. {model['name']} (uid: {model['uid']})\")\n",
    "            \n",
    "            all_model_info.extend(models)\n",
    "            \n",
    "            if auto_download and models:\n",
    "                # Download the most popular model (first result)\n",
    "                best_model = models[0]\n",
    "                print(f\"Auto-downloading: {best_model['name']}\")\n",
    "                \n",
    "                file_path = self.download_model(best_model['uid'], obj)\n",
    "                if file_path:\n",
    "                    downloaded_models[obj] = file_path\n",
    "                \n",
    "                # Be nice to the API\n",
    "                time.sleep(1)\n",
    "        \n",
    "        # Inject downloaded models into HTML\n",
    "        enhanced_html = self.inject_gltf_into_html(generated_html, downloaded_models)\n",
    "        \n",
    "        return enhanced_html, all_model_info\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    import re\n",
    "    from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "    import torch\n",
    "    \n",
    "    # You need to get your API token from: https://sketchfab.com/settings/password\n",
    "    API_TOKEN = \"YOUR_SKETCHFAB_API_TOKEN_HERE\"\n",
    "    \n",
    "    # Load your trained model\n",
    "    model = AutoModelForCausalLM.from_pretrained(\"./qwen_sft_vr_run2/final\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"./qwen_sft_vr_run2/final\")\n",
    "    \n",
    "    # Move model to GPU if available\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Initialize integrator\n",
    "    integrator = SketchfabGLTFIntegrator(api_token=API_TOKEN)\n",
    "    \n",
    "    # Generate HTML\n",
    "    prompt = \"A scene with a sports car and a skyscraper\"\n",
    "    inputs = tokenizer(prompt + \"\\nHTML_START\\n\", return_tensors=\"pt\").to(device)\n",
    "    outputs = model.generate(**inputs, max_new_tokens=1200)\n",
    "    generated_html = tokenizer.decode(outputs[0])\n",
    "    \n",
    "    # Extract just the HTML part\n",
    "    html_match = re.search(r'HTML_START\\n(.*?)HTML_END', generated_html, re.DOTALL)\n",
    "    if html_match:\n",
    "        html_content = html_match.group(1)\n",
    "        \n",
    "        # Enhance with Sketchfab models\n",
    "        enhanced_html, models = integrator.process_prompt_and_enhance_html(\n",
    "            prompt, \n",
    "            html_content,\n",
    "            auto_download=True\n",
    "        )\n",
    "        \n",
    "        # Save result\n",
    "        with open(\"final_scene.html\", \"w\") as f:\n",
    "            f.write(enhanced_html)\n",
    "        \n",
    "        print(f\"\\nEnhanced HTML saved to final_scene.html\")\n",
    "        print(f\"Total models found: {len(models)}\")\n",
    "    else:\n",
    "        print(\"Could not extract HTML from generated output\") "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
